{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task1 Evaluation of the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision as tv\n",
    "from torchvision import transforms, datasets\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.optim as optim "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the CNN from the saved data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_test='./cats_and_dogs_filtered/validation/'\n",
    "batch_size_test = 100 \n",
    "batch_size_train = 100 \n",
    "num_workers_test = 0 \n",
    "num_workers_train = 0 \n",
    "size_compressed = [80,80]\n",
    "# to load the parameters of the net saved before, construct the net with the same structure at first\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        # here we use a neural network contains 2 types of the neural networks, a convolution network for the feature extraction\n",
    "        # and a fully connected layer to realize the classification \n",
    "        # ===========================================================================\n",
    "        # define the number of filters in the CNNs for features extraction\n",
    "        num_filters = [1, 64, 64, 128, 128]\n",
    "        # define the number of the nodes in the fully connected layers for classification\n",
    "        num_NN = [256, 64]\n",
    "        self.con1 = nn.Conv2d(in_channels = num_filters[0],\n",
    "                      out_channels = num_filters[1], \n",
    "                      kernel_size = 5, \n",
    "                      padding = 1,\n",
    "                      bias = False)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.bn1 = nn.BatchNorm2d(num_features=num_filters[1])\n",
    "        self.con2= nn.Conv2d(in_channels = num_filters[1],\n",
    "                      out_channels = num_filters[2], \n",
    "                      kernel_size = 3, \n",
    "                      padding = 1,\n",
    "                      bias = False)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.bn2 = nn.BatchNorm2d(num_features=num_filters[2])\n",
    "        self.con3 = nn.Conv2d(in_channels = num_filters[2],\n",
    "                      out_channels = num_filters[3], \n",
    "                      kernel_size = 3, \n",
    "                      padding = 1,\n",
    "                      bias = False)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.bn3 = nn.BatchNorm2d(num_features=num_filters[3])\n",
    "        self.con4 = nn.Conv2d(in_channels = num_filters[3],\n",
    "                      out_channels = num_filters[4], \n",
    "                      kernel_size = 3, \n",
    "                      padding = 1,\n",
    "                      bias = False)\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.bn4 = nn.BatchNorm2d(num_features=num_filters[4])\n",
    "        self.fc1 = nn.Linear(num_filters[4]*4*4,num_NN[0])\n",
    "        self.fc2 = nn.Linear(num_NN[0],num_NN[1])\n",
    "        self.fc3 = nn.Linear(num_NN[1],2)\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.bn1(self.con1(x))))\n",
    "        x = self.pool2(F.relu(self.bn2(self.con2(x))))\n",
    "        x = self.pool3(F.relu(self.bn3(self.con3(x))))\n",
    "        x = self.pool4(F.relu(self.bn4(self.con4(x))))\n",
    "        x = x.view(-1, 128*4*4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "kaggle_Net = CNN()\n",
    "kaggle_Net = torch.load('.\\kaggle_Net.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test dataset preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transform = tv.transforms.Compose([\n",
    "    tv.transforms.Grayscale(num_output_channels=1), # reduce the channel Nr to one\n",
    "    tv.transforms.Resize(size_compressed),\n",
    "    tv.transforms.ToTensor()\n",
    "])\n",
    "test_data = tv.datasets.ImageFolder(root = path_test, transform = test_transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size = batch_size_test,\n",
    "                                           num_workers = num_workers_test, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the error rate given test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error rate on test set: 24.1 %\n"
     ]
    }
   ],
   "source": [
    "errors_test = 0\n",
    "for batch_idx , data in enumerate(test_loader,0):\n",
    "    inputs, labels = data\n",
    "    outputs = kaggle_Net(inputs)\n",
    "    # error rate\n",
    "    predicted = torch.max(outputs,dim=1)\n",
    "    errors_test += sum(predicted[1] != labels)\n",
    "print('Error rate on test set:', round(100.0* errors_test.numpy() / len(test_loader.dataset),2), '%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
